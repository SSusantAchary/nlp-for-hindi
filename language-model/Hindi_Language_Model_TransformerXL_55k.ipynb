{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.57', '1.1.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 13 21:12:00 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 390.116                Driver Version: 390.116                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "|  0%   55C    P8    14W / 250W |    262MiB / 11177MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1039      G   /usr/lib/xorg/Xorg                           117MiB |\r\n",
      "|    0      2165      G   compiz                                       132MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gaurav/PycharmProjects/nlp-for-hindi/language-model\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/gaurav/PycharmProjects/nlp-for-hindi/language-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_files, test_files = train_test_split(files, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_files), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str(train_files[0]).split('/')[-1][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preparing dataset for fastai\n",
    "# for file in train_files:\n",
    "#     with open(file, 'rb') as f:\n",
    "#         text = pickle.load(f)\n",
    "#     with open(path/'hindi_transformer'/'train'/(str(file).split('/')[-1][:-4]+'.txt'), \"w\") as text_file:\n",
    "#         text_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in test_files:\n",
    "#     with open(file, 'rb') as f:\n",
    "#         text = pickle.load(f)\n",
    "#     with open(path/'hindi_transformer'/'valid'/(str(file).split('/')[-1][:-4]+'.txt'), \"w\") as text_file:\n",
    "#         text_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from inltk.tokenizer import HindiTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HindiTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/gaurav/PycharmProjects/nlp-for-hindi/language-model')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HindiTokenizer(BaseTokenizer):\n",
    "    def __init__(self, lang:str):\n",
    "        self.lang = lang\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.Load(str(path/\"../tokenizer/hindi_lm_large.model\"))\n",
    "        \n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(path/\"../tokenizer/hindi_lm_large.model\"))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(30000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<s>',\n",
       " '</s>',\n",
       " '▁के',\n",
       " '।',\n",
       " '▁में',\n",
       " '▁है',\n",
       " ',',\n",
       " '▁की',\n",
       " '▁',\n",
       " '▁और',\n",
       " '▁से',\n",
       " '▁का',\n",
       " '▁को',\n",
       " '▁हैं',\n",
       " '▁एक',\n",
       " '▁पर',\n",
       " '.',\n",
       " '-',\n",
       " '▁ने']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30,000 is the vocab size that we chose in sentencepiece\n",
    "hindi_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(tok_func=HindiTokenizer, lang='hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_folder(path=path/'HindiDataset', tokenizer=tokenizer, vocab=hindi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>▁भारतीय ▁धातुकर्म ▁की ▁पराकाष्ठा ▁है । ▁यह ▁कथित ▁रूप ▁से ▁राजा ▁चन्द्रगुप्त ▁विक्रमादित्य ▁से ▁निर्माण ▁कराया ▁गया , ▁किंतु ▁कुछ ▁विशेषज्ञों ▁का ▁मानना ▁है ▁कि ▁इसके ▁पहले ▁निर्माण ▁किया ▁गया , ▁संभवतः ▁9 12 ▁ईपू ▁में । ▁स्तंभ ▁की ▁उँचाई ▁लगभग ▁सात ▁मीटर ▁है ▁और ▁पहले ▁हिंदू ▁व ▁जैन ▁मंदिर ▁का ▁एक ▁हिस्सा ▁था । ▁तेरहवीं ▁सदी ▁में ▁कुतुबुद्दीन ▁ऐबक ▁ने ▁मंदिर ▁को ▁नष्ट ▁करके ▁क़ुतुब ▁मीनार ▁की ▁स्थापना ▁की</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>▁की ▁विस्तृत ▁तालिका ▁देना ▁सर्वथा ▁असंभव ▁है ▁जिन ▁दशाओं ▁में ▁उच्च ▁न्यायालय ▁अपनी ▁शक्ति ▁का ▁प्रयोग ▁करना ▁अस्वीकार ▁कर ▁सकता ▁है । ▁प्रत्येक ▁मामले ▁की ▁परिस्थिति , ▁प्रकृति ▁उद्देश्य ▁तथा ▁शक्ति ▁के ▁विस्तार य ▁को ▁दृष्टिगत ▁रखकर ▁ही ▁न्यायालय ▁अपने ▁न्यायिक ▁विवेक ▁का ▁प्रयोग ▁करेगा । ▁सामान्यत : ▁मामले ▁से ▁प्रत्यक्ष ▁रूप ▁ते ▁सम्बन्धित ▁व्यक्ति ▁ही ▁सर्वोच्च ▁न्यायालय ▁अथवा ▁उच्च ▁न्यायालयों ▁से ▁उनकी ▁शक्ति ▁के ▁प्रयोग ▁की ▁याचना ▁कर ▁सकता</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>▁आमतौर ▁पर ▁इस्तेमाल ▁किए ▁जाने ▁वाले ▁पौधे ▁और ▁पशुओं ▁के ▁नाम ▁को ▁ट क्स ा ▁कभी - कभी ▁इन ▁जातियों ▁के ▁समान ▁होते ▁हैं : ▁जैसे , ▁\" शेर \", ▁\" वॉल रस , \" ▁और ▁\" क पूर ▁का ▁पेड़ \" ▁- ▁प्रत्येक ▁जातियों ▁को ▁दर्शाते ▁हैं । ▁अन्य ▁मामले ▁जिनमें ▁उन ▁नाम ▁का ▁प्रयोग ▁नहीं ▁होता : ▁\" हिर ण \" ▁34 ▁जातियों ▁के ▁वर्ग ▁को ▁दर्शाता ▁है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁मूल ▁क्षेत्र ▁दक्षिण ▁पूर्वी ▁एशिया के ▁बाहर ▁दुर्लभ ▁होने ▁कि ▁वजह ▁से ▁अधिकांश ▁लोग ▁लाइक ोप ीन ▁के ▁लिए ▁आहार ▁के ▁मुख्य ▁स्रोत ▁के ▁तौर ▁पर ▁अर्थात् ▁85% ▁से ▁अधिक ▁टमाटर ▁और ▁टमाटर ▁आधारित ▁सॉ स , ▁जू स ▁और ▁के च प ▁का ▁सेवन ▁करते ▁हैं । ▁टमाटर ▁में ▁लाइक ो पेन ▁की ▁मात्रा ▁इसकी ▁प्रजातियों ▁पर ▁निर्भर ▁करती ▁है ▁और ▁फल ▁के ▁पकने ▁के ▁साथ - साथ ▁बढ़</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>▁के ▁होते ▁हैं , ▁एक ▁तो ▁पूरे ▁दाँत ▁और ▁दूसरे ▁दंत शिखर ▁मात्र । ▁नकली ▁दाँत ▁बनाने ▁का ▁प्रचलन ▁बहुत ▁पुराना ▁है । ▁पहले ▁हड्डी , ▁हाथी ▁दाँत , ▁हिप्पो ▁या ▁आदमी ▁के ▁दाँत ▁को ▁सोने ▁या ▁हाथी ▁दाँत ▁के ▁आधार ▁पर ▁बैठा कर ▁लगाते ▁थे । ▁18 वीं ▁शताब्दी ▁से ▁पो र्स िले न ▁के ▁दाँतों ▁का ▁प्रचलन ▁आरंभ ▁हुआ । ▁सन् ▁1860 ▁में ▁आधार ▁के ▁लिये ▁वल् कन</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "??language_model_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, TransformerXL, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): TransformerXL(\n",
       "    (encoder): Embedding(30000, 410)\n",
       "    (pos_enc): PositionalEncoding()\n",
       "    (drop_emb): Dropout(p=0.1)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=410, out_features=30000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.607016</td>\n",
       "      <td>5.545075</td>\n",
       "      <td>0.221256</td>\n",
       "      <td>25:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.001612</td>\n",
       "      <td>4.997944</td>\n",
       "      <td>0.259239</td>\n",
       "      <td>26:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.548926</td>\n",
       "      <td>4.565289</td>\n",
       "      <td>0.291202</td>\n",
       "      <td>26:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.382370</td>\n",
       "      <td>4.402876</td>\n",
       "      <td>0.302148</td>\n",
       "      <td>26:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.389576</td>\n",
       "      <td>4.357889</td>\n",
       "      <td>0.303309</td>\n",
       "      <td>26:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.228850</td>\n",
       "      <td>4.252396</td>\n",
       "      <td>0.310255</td>\n",
       "      <td>26:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.176673</td>\n",
       "      <td>4.189835</td>\n",
       "      <td>0.315705</td>\n",
       "      <td>26:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.143566</td>\n",
       "      <td>4.124595</td>\n",
       "      <td>0.320588</td>\n",
       "      <td>26:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.135462</td>\n",
       "      <td>4.051057</td>\n",
       "      <td>0.328533</td>\n",
       "      <td>26:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.985274</td>\n",
       "      <td>3.983402</td>\n",
       "      <td>0.334741</td>\n",
       "      <td>26:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.889116</td>\n",
       "      <td>3.920001</td>\n",
       "      <td>0.341589</td>\n",
       "      <td>26:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.843901</td>\n",
       "      <td>3.846541</td>\n",
       "      <td>0.349629</td>\n",
       "      <td>26:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.711715</td>\n",
       "      <td>3.784675</td>\n",
       "      <td>0.357161</td>\n",
       "      <td>26:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.759037</td>\n",
       "      <td>3.721314</td>\n",
       "      <td>0.364985</td>\n",
       "      <td>26:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.625584</td>\n",
       "      <td>3.667374</td>\n",
       "      <td>0.371980</td>\n",
       "      <td>26:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.455709</td>\n",
       "      <td>3.619851</td>\n",
       "      <td>0.378364</td>\n",
       "      <td>26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.467026</td>\n",
       "      <td>3.582810</td>\n",
       "      <td>0.383214</td>\n",
       "      <td>26:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.538625</td>\n",
       "      <td>3.561144</td>\n",
       "      <td>0.386417</td>\n",
       "      <td>26:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.406899</td>\n",
       "      <td>3.551317</td>\n",
       "      <td>0.387995</td>\n",
       "      <td>26:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.503951</td>\n",
       "      <td>3.549155</td>\n",
       "      <td>0.388337</td>\n",
       "      <td>26:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.22125616669654846.\n",
      "Better model found at epoch 1 with accuracy value: 0.2592393457889557.\n",
      "Better model found at epoch 2 with accuracy value: 0.291202187538147.\n",
      "Better model found at epoch 3 with accuracy value: 0.30214783549308777.\n",
      "Better model found at epoch 4 with accuracy value: 0.3033091127872467.\n",
      "Better model found at epoch 5 with accuracy value: 0.310255229473114.\n",
      "Better model found at epoch 6 with accuracy value: 0.3157047927379608.\n",
      "Better model found at epoch 7 with accuracy value: 0.32058843970298767.\n",
      "Better model found at epoch 8 with accuracy value: 0.3285328149795532.\n",
      "Better model found at epoch 9 with accuracy value: 0.33474060893058777.\n",
      "Better model found at epoch 10 with accuracy value: 0.3415887951850891.\n",
      "Better model found at epoch 11 with accuracy value: 0.34962937235832214.\n",
      "Better model found at epoch 12 with accuracy value: 0.35716062784194946.\n",
      "Better model found at epoch 13 with accuracy value: 0.3649854362010956.\n",
      "Better model found at epoch 14 with accuracy value: 0.3719800114631653.\n",
      "Better model found at epoch 15 with accuracy value: 0.3783637285232544.\n",
      "Better model found at epoch 16 with accuracy value: 0.38321399688720703.\n",
      "Better model found at epoch 17 with accuracy value: 0.38641655445098877.\n",
      "Better model found at epoch 18 with accuracy value: 0.38799455761909485.\n",
      "Better model found at epoch 19 with accuracy value: 0.3883371949195862.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(20, 1e-3, moms=(0.8,0.7), callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='model')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"जिसके लिये उन्हें \"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "जिसके लिये उन्हें  ▁सही ▁कर ▁देने ▁से ▁पहले ▁कम बेस ▁की ▁आवश्यकता ▁होती ▁है । ▁x x bo s ▁अ जान जान ▁विमानक्षेत्र ▁एक ▁अ जान जान ▁धर्मशाला ▁है ▁जो ▁दक्षिण ▁एशिया ▁में ▁स्थित ▁है । ▁इसका ▁नामकरण ▁मंगोल ▁भाषा ▁के ▁अ जान\n",
      "जिसके लिये उन्हें  ▁निदेशक ▁का ▁ हस ▁शेन ▁दिया ▁जाता ▁है । ▁x x bo s ▁भारतीय ▁रेलवे ▁का ▁एक ▁प्रमुख ▁रेलवे ▁स्टेशन । ▁x x bo s ▁भारत ▁के ▁ऐतिहासिक ▁एवं ▁शैक्षणिक ▁केंद्रों ▁में ▁अवस्थिति ▁की ▁दृष्टि ▁से ▁भारत ▁लिये ▁मे वाड\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.9) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.783912659614465"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.549155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')\n",
    "learn.model.eval()\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/gaurav/PycharmProjects/nlp-for-hindi/language-model')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = load_learner(path / 'HindiDataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_model(learn.model)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30000, 410])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder.state_dict()['encoder.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 410)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('transformer2_embeddings.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "      <th>409</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.026936</td>\n",
       "      <td>-0.117357</td>\n",
       "      <td>-0.120443</td>\n",
       "      <td>0.065017</td>\n",
       "      <td>0.166728</td>\n",
       "      <td>-0.071703</td>\n",
       "      <td>-0.291924</td>\n",
       "      <td>-0.226281</td>\n",
       "      <td>-0.153028</td>\n",
       "      <td>-0.018027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194817</td>\n",
       "      <td>-0.072590</td>\n",
       "      <td>0.070672</td>\n",
       "      <td>-0.063407</td>\n",
       "      <td>-0.164804</td>\n",
       "      <td>0.109832</td>\n",
       "      <td>-0.060472</td>\n",
       "      <td>-0.060639</td>\n",
       "      <td>-0.072969</td>\n",
       "      <td>0.029148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.052435</td>\n",
       "      <td>-0.122068</td>\n",
       "      <td>-0.217137</td>\n",
       "      <td>-0.030436</td>\n",
       "      <td>-0.187478</td>\n",
       "      <td>-0.400876</td>\n",
       "      <td>0.065107</td>\n",
       "      <td>-0.087606</td>\n",
       "      <td>-0.270060</td>\n",
       "      <td>0.043844</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>0.013643</td>\n",
       "      <td>0.142191</td>\n",
       "      <td>-0.138822</td>\n",
       "      <td>-0.004607</td>\n",
       "      <td>-0.216894</td>\n",
       "      <td>0.018326</td>\n",
       "      <td>-0.265118</td>\n",
       "      <td>-0.156099</td>\n",
       "      <td>-0.165192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.052706</td>\n",
       "      <td>-0.127456</td>\n",
       "      <td>-0.216761</td>\n",
       "      <td>-0.027200</td>\n",
       "      <td>-0.182869</td>\n",
       "      <td>-0.407149</td>\n",
       "      <td>0.062482</td>\n",
       "      <td>-0.092614</td>\n",
       "      <td>-0.265342</td>\n",
       "      <td>0.042330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025513</td>\n",
       "      <td>0.017536</td>\n",
       "      <td>0.141987</td>\n",
       "      <td>-0.138726</td>\n",
       "      <td>-0.002742</td>\n",
       "      <td>-0.214716</td>\n",
       "      <td>0.025111</td>\n",
       "      <td>-0.261457</td>\n",
       "      <td>-0.157117</td>\n",
       "      <td>-0.165897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.086347</td>\n",
       "      <td>0.081104</td>\n",
       "      <td>-0.239553</td>\n",
       "      <td>-0.080807</td>\n",
       "      <td>0.012266</td>\n",
       "      <td>-0.081333</td>\n",
       "      <td>-0.273898</td>\n",
       "      <td>-0.359493</td>\n",
       "      <td>0.531257</td>\n",
       "      <td>0.199352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523504</td>\n",
       "      <td>0.049788</td>\n",
       "      <td>0.038321</td>\n",
       "      <td>-0.216122</td>\n",
       "      <td>0.044788</td>\n",
       "      <td>0.191416</td>\n",
       "      <td>-0.224508</td>\n",
       "      <td>-0.005013</td>\n",
       "      <td>0.074293</td>\n",
       "      <td>0.030674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.234804</td>\n",
       "      <td>-0.233256</td>\n",
       "      <td>-0.023235</td>\n",
       "      <td>-0.176765</td>\n",
       "      <td>-0.480278</td>\n",
       "      <td>-0.028081</td>\n",
       "      <td>-0.298427</td>\n",
       "      <td>0.017335</td>\n",
       "      <td>0.316586</td>\n",
       "      <td>-0.011410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.486305</td>\n",
       "      <td>-0.153151</td>\n",
       "      <td>-0.119705</td>\n",
       "      <td>-0.170665</td>\n",
       "      <td>-0.090154</td>\n",
       "      <td>0.081009</td>\n",
       "      <td>-0.184804</td>\n",
       "      <td>0.198799</td>\n",
       "      <td>0.147589</td>\n",
       "      <td>0.084772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.026936 -0.117357 -0.120443  0.065017  0.166728 -0.071703 -0.291924   \n",
       "1 -0.052435 -0.122068 -0.217137 -0.030436 -0.187478 -0.400876  0.065107   \n",
       "2 -0.052706 -0.127456 -0.216761 -0.027200 -0.182869 -0.407149  0.062482   \n",
       "3  0.086347  0.081104 -0.239553 -0.080807  0.012266 -0.081333 -0.273898   \n",
       "4 -0.234804 -0.233256 -0.023235 -0.176765 -0.480278 -0.028081 -0.298427   \n",
       "\n",
       "        7         8         9    ...       400       401       402       403  \\\n",
       "0 -0.226281 -0.153028 -0.018027  ...  0.194817 -0.072590  0.070672 -0.063407   \n",
       "1 -0.087606 -0.270060  0.043844  ... -0.037097  0.013643  0.142191 -0.138822   \n",
       "2 -0.092614 -0.265342  0.042330  ... -0.025513  0.017536  0.141987 -0.138726   \n",
       "3 -0.359493  0.531257  0.199352  ...  0.523504  0.049788  0.038321 -0.216122   \n",
       "4  0.017335  0.316586 -0.011410  ... -0.486305 -0.153151 -0.119705 -0.170665   \n",
       "\n",
       "        404       405       406       407       408       409  \n",
       "0 -0.164804  0.109832 -0.060472 -0.060639 -0.072969  0.029148  \n",
       "1 -0.004607 -0.216894  0.018326 -0.265118 -0.156099 -0.165192  \n",
       "2 -0.002742 -0.214716  0.025111 -0.261457 -0.157117 -0.165897  \n",
       "3  0.044788  0.191416 -0.224508 -0.005013  0.074293  0.030674  \n",
       "4 -0.090154  0.081009 -0.184804  0.198799  0.147589  0.084772  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 410)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁के</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  <unk>\n",
       "1    <s>\n",
       "2   </s>\n",
       "3    ▁के\n",
       "4      ।"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('transformer2_embeddings_metadata.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.2435e-02, -1.2207e-01, -2.1714e-01, -3.0436e-02, -1.8748e-01,\n",
       "        -4.0088e-01,  6.5107e-02, -8.7606e-02, -2.7006e-01,  4.3844e-02,\n",
       "        -1.4409e-01,  6.9624e-02, -2.4151e-01, -9.3456e-03, -1.0605e-01,\n",
       "        -6.1454e-02, -1.5840e-01,  1.6378e-01, -1.8422e-01, -1.1712e-01,\n",
       "         1.3616e-01, -2.1405e-01,  1.3627e-01,  7.0656e-02,  5.9272e-03,\n",
       "        -1.7993e-01, -1.2620e-01,  1.6521e-01, -2.0209e-01,  4.1299e-02,\n",
       "        -8.3203e-02,  1.5346e-01, -3.2722e-01, -1.0124e-01, -1.8463e-01,\n",
       "        -6.0260e-03, -3.7177e-02,  1.0092e-01,  1.1096e-01,  6.6525e-02,\n",
       "         3.4547e-01, -1.9262e-01, -1.1953e-01,  1.1277e-01, -2.3187e-02,\n",
       "        -2.6035e-02, -1.4045e-01, -3.1236e-01, -6.9377e-02,  1.3386e-01,\n",
       "        -1.7842e-01,  1.5998e-01, -9.7051e-02, -7.6790e-02, -1.9065e-01,\n",
       "        -2.0835e-01,  1.8482e-01, -5.3779e-02,  2.9594e-01, -1.2866e-02,\n",
       "         1.4117e-01, -1.4633e-01, -1.2209e-01,  4.2426e-01, -5.9861e-02,\n",
       "        -1.6373e-01,  6.5469e-02, -3.7790e-01,  5.5360e-02,  2.6953e-02,\n",
       "         3.5151e-02, -1.6676e-01, -1.3716e-01,  2.0795e-01,  9.3364e-03,\n",
       "         1.6515e-01, -2.2157e-01, -1.5899e-01, -1.2818e-01, -9.1754e-02,\n",
       "        -1.6371e-01,  7.8255e-02, -4.9570e-02,  2.8136e-01,  1.1548e-01,\n",
       "        -3.1679e-01, -4.0917e-02,  2.6239e-01, -2.4441e-01, -1.5765e-01,\n",
       "        -1.1188e-02, -8.1556e-02, -3.8247e-01, -7.2761e-03,  1.9796e-01,\n",
       "        -9.7261e-02, -2.8889e-01, -7.8105e-02,  1.6634e-01,  4.0357e-02,\n",
       "         6.7865e-02, -2.8970e-01,  4.5648e-02, -3.4972e-01, -9.7186e-02,\n",
       "        -5.9626e-02,  1.5967e-01,  1.2628e-02,  1.7418e-01,  2.9262e-01,\n",
       "         2.2590e-01, -7.6840e-03, -2.2029e-01, -8.0941e-02,  1.3183e-01,\n",
       "         1.7933e-01, -4.1513e-02,  1.0489e-01,  1.8313e-02,  5.9334e-02,\n",
       "         1.0837e-01, -2.5087e-03,  2.1432e-02, -1.1289e-01, -2.0616e-01,\n",
       "        -7.2432e-02,  1.1797e-01,  1.7261e-01, -2.4593e-03, -5.6042e-04,\n",
       "         1.2936e-01,  1.2013e-01, -9.2885e-02, -3.5839e-01,  1.1719e-01,\n",
       "        -1.7821e-02,  3.4563e-02, -4.2626e-02, -7.0163e-02, -1.2558e-01,\n",
       "        -3.2742e-02,  6.2785e-03, -2.1094e-01, -2.7498e-01,  2.2380e-01,\n",
       "         1.9207e-02,  9.1182e-02,  3.0853e-02, -7.7076e-02, -3.3209e-02,\n",
       "         2.6362e-01,  1.1746e-01,  1.0409e-01,  2.1597e-01,  1.6697e-01,\n",
       "         1.7248e-02,  1.7663e-01, -4.4266e-02, -6.2422e-03,  4.5435e-03,\n",
       "        -2.4179e-02, -1.1572e-02,  1.8548e-02,  5.0471e-02,  9.9426e-02,\n",
       "        -1.7100e-03, -8.8831e-02, -4.6239e-02,  4.3133e-01, -2.8199e-01,\n",
       "         1.1816e-02,  5.8656e-02, -8.4020e-02,  5.3891e-02, -2.4378e-01,\n",
       "         7.5393e-02,  1.5528e-01, -1.2179e-01,  1.2833e-02, -3.6296e-02,\n",
       "         1.4552e-02,  4.1532e-02,  3.3860e-01,  2.8802e-01, -6.6649e-04,\n",
       "         8.2851e-02, -3.2243e-02, -2.6633e-02,  2.3623e-01,  2.6348e-02,\n",
       "         1.5457e-01,  4.6524e-02, -3.6108e-02,  5.1407e-02, -3.2914e-02,\n",
       "         1.6950e-01,  1.5043e-01,  5.6069e-02,  1.8487e-01, -1.4371e-01,\n",
       "         2.2101e-02, -1.3886e-01, -1.4193e-01,  1.5947e-01,  2.8884e-03,\n",
       "         2.8342e-01, -8.7530e-02, -9.7725e-02, -3.8377e-02, -6.1606e-02,\n",
       "         9.9139e-02, -1.0914e-01, -1.1862e-01, -5.5928e-01,  1.6774e-01,\n",
       "         1.0684e-01, -2.4943e-01, -2.8686e-01,  1.1795e-01,  2.1539e-02,\n",
       "         2.0309e-01, -1.0168e-01,  7.7424e-02, -2.0047e-01,  2.6893e-02,\n",
       "        -1.3814e-01,  2.3796e-01,  2.0036e-01, -1.5329e-01, -1.1348e-03,\n",
       "         8.3308e-02, -4.6813e-01, -1.8245e-01,  2.5423e-01,  6.4910e-02,\n",
       "        -3.0732e-02, -6.2937e-02,  1.0243e-02, -1.0658e-01, -4.1709e-02,\n",
       "        -1.5275e-01, -5.8817e-02, -3.0486e-01, -9.0957e-02,  4.2878e-02,\n",
       "        -2.5885e-01,  3.9249e-02,  7.7869e-02, -1.6303e-01, -8.1910e-02,\n",
       "        -2.0764e-01,  2.7059e-02,  1.7683e-01,  6.1407e-02,  1.0145e-01,\n",
       "         2.0315e-01,  4.3002e-02, -8.3692e-02, -1.2385e-01,  2.2157e-01,\n",
       "         8.1188e-02, -5.1648e-02, -1.7297e-01,  9.0141e-02,  6.5017e-01,\n",
       "        -1.1285e-01, -5.9874e-02,  2.6574e-02, -1.5389e-01,  2.6061e-01,\n",
       "        -2.0248e-01, -1.0784e-01, -2.1070e-01,  2.8795e-02, -9.7251e-02,\n",
       "         1.0330e-01,  1.6849e-01, -8.8714e-02,  1.7416e-01, -2.9727e-01,\n",
       "         2.5712e-01, -8.4791e-02, -3.9877e-02,  1.2872e-01,  6.0207e-02,\n",
       "        -2.8914e-03, -8.6100e-02,  1.9533e-01,  2.5660e-02, -2.2969e-02,\n",
       "        -2.6801e-01, -3.7978e-01,  2.4261e-01,  7.4164e-02, -1.3153e-01,\n",
       "        -2.1617e-01,  1.4600e-01,  2.7130e-01,  4.2249e-01, -2.1126e-01,\n",
       "        -6.2353e-02, -5.9195e-02,  1.1555e-01,  7.7651e-02, -1.3070e-01,\n",
       "        -1.3736e-01, -2.3601e-01, -3.3056e-03, -3.5076e-02,  3.3803e-01,\n",
       "         3.7545e-02, -5.1797e-02, -1.5481e-01, -2.6018e-01, -8.2185e-02,\n",
       "        -1.5635e-01, -2.4679e-01, -7.8857e-02,  3.7184e-02,  4.7333e-01,\n",
       "         2.4615e-01, -4.2077e-02, -2.4912e-01, -1.4978e-01,  1.3454e-01,\n",
       "        -6.5693e-02,  4.2260e-02, -4.1035e-02,  9.2347e-02, -1.7356e-01,\n",
       "        -1.6033e-02, -4.2382e-02,  6.5841e-02,  2.0498e-01,  1.0573e-01,\n",
       "         1.2703e-01,  1.1582e-01,  2.1511e-01, -1.9121e-01, -1.0781e-01,\n",
       "         2.2839e-01,  9.5185e-02, -8.4903e-02, -1.0879e-01, -3.0743e-01,\n",
       "         2.6838e-02,  1.1664e-01, -5.2443e-02,  1.1945e-01, -1.5533e-01,\n",
       "        -1.1641e-01,  7.7206e-02,  6.2701e-02, -1.3568e-01,  7.3817e-02,\n",
       "        -2.0241e-01, -1.0017e-01, -3.4305e-01,  1.7806e-01,  5.2516e-02,\n",
       "         5.8831e-01,  1.4527e-01,  1.2428e-01,  3.6125e-02,  2.0617e-01,\n",
       "         2.8748e-01,  4.5458e-02,  3.2024e-02,  1.4450e-01, -1.4824e-01,\n",
       "         2.1268e-01,  6.4470e-01, -2.2587e-02,  1.1292e-01, -1.0771e-01,\n",
       "         6.3910e-02, -1.8772e-02, -1.4595e-01, -1.6034e-01, -1.6040e-01,\n",
       "         1.4532e-01, -5.7659e-02, -2.3052e-03,  5.6685e-02, -3.2035e-01,\n",
       "         1.9956e-01,  4.8962e-03, -1.8754e-01,  2.2948e-01,  2.9977e-02,\n",
       "        -1.7168e-01,  1.6856e-02,  8.5007e-02, -3.7947e-01, -1.6178e-01,\n",
       "         2.1526e-01,  2.5307e-02,  1.6365e-01, -1.2721e-01,  2.8023e-02,\n",
       "        -3.7097e-02,  1.3643e-02,  1.4219e-01, -1.3882e-01, -4.6072e-03,\n",
       "        -2.1689e-01,  1.8326e-02, -2.6512e-01, -1.5610e-01, -1.6519e-01],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
